{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "234afff3",
   "metadata": {},
   "source": [
    "## Geneformer Fine-Tuning for Cell Annotation Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9885d9f-00ac-4c84-b6a3-b7b648a90f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 16:05:18.825588: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-10 16:05:21.629728: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import pickle\n",
    "import subprocess\n",
    "import seaborn as sns; sns.set()\n",
    "from datasets import load_from_disk\n",
    "import datasets\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer\n",
    "from transformers.training_args import TrainingArguments\n",
    "\n",
    "from geneformer import DataCollatorForCellClassification\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24e1ab7-0131-44bd-b458-1ce5ba31853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model parameters\n",
    "# max input size\n",
    "max_input_size = 2 ** 11  # 2048\n",
    "\n",
    "# set training parameters\n",
    "# max learning rate\n",
    "max_lr = 5e-5\n",
    "# how many pretrained layers to freeze\n",
    "freeze_layers = 0\n",
    "# number gpus\n",
    "num_gpus = 4\n",
    "# number cpu cores\n",
    "num_proc = 16\n",
    "# batch size for training and eval. Note that during train cycle space will look free but eval will fill it\n",
    "geneformer_batch_size = 6\n",
    "# learning schedule\n",
    "lr_schedule_fn = \"linear\"\n",
    "# warmup steps\n",
    "warmup_steps = 500\n",
    "# number of epochs\n",
    "epochs = 10\n",
    "# optimizer\n",
    "optimizer = \"adamw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c58f47a-46db-45b5-824b-db34198f51e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save model artifact\n",
    "model_save_dir = \"/home/domino/geneformer_workflow/results/perturbation/finetuned_model\"\n",
    "\n",
    "# Where to load pretrained model from. This is location on Huggingface but could be custom\n",
    "pretrained_model_path = \"/home/domino/geneformer_workflow/Geneformer\"\n",
    "\n",
    "tokenized_input_dir = \"/home/domino/geneformer_workflow/results/perturbation/tokenized_files\"\n",
    "tokenized_input_prefix = \"adata_SS2\"\n",
    "\n",
    "\n",
    "# Name of column storing cell class labels\n",
    "label_colname = \"celltype\"\n",
    "\n",
    "processed_dataset_output_dir = \"/home/domino/geneformer_workflow/results/perturbation/processed_dataset\"\n",
    "os.makedirs(processed_dataset_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd3b98-5409-4105-b7af-f1ff64ea6a72",
   "metadata": {},
   "source": [
    "## Prepare training and evaluation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5735f1b7-7595-4a02-be17-2c5b970ad81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset (includes all tissues)\n",
    "full_dataset=load_from_disk(os.path.join(tokenized_input_dir, tokenized_input_prefix + \".dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8777e3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'n_counts', 'celltype', 'length'],\n",
       "    num_rows: 1333\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b90f1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'USM': 501, 'SM': 458, 'N': 374})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(full_dataset[label_colname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb01391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of cell types : label ids\n",
    "target_names = list(Counter(full_dataset[label_colname]).keys())\n",
    "target_name_id_dict = dict(zip(target_names,[i for i in range(len(target_names))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e662a275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N': 0, 'USM': 1, 'SM': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_name_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3187dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change labels to numerical ids\n",
    "def classes_to_ids(example):\n",
    "    example[\"label\"] = target_name_id_dict[example[label_colname]]\n",
    "    return example\n",
    "full_dataset = full_dataset.map(classes_to_ids, num_proc=num_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abe36c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'n_counts', 'celltype', 'length', 'label'],\n",
       "    num_rows: 1333\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "173ede94",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = full_dataset.remove_columns(label_colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30992b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508b198d02d9407f8ca9df107f9fdc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1333 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_dataset.save_to_disk(os.path.join(processed_dataset_output_dir, tokenized_input_prefix + \".dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41b97970",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = full_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = split_dataset['train']\n",
    "eval_dataset = split_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccbf35d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1333\n",
      "1199\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "print(len(full_dataset))\n",
    "print(len(train_dataset))\n",
    "print(len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a15ca172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 455, 2: 415, 0: 329})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24075c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 46, 0: 45, 2: 43})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(eval_dataset['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb110d-ba43-4efc-bc43-1815d6912647",
   "metadata": {},
   "source": [
    "## Fine-Tune With Cell Classification Learning Objective and Quantify Predictive Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd7b1cfb-f5cb-460e-ae77-769522ece054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average='macro')\n",
    "    return {\n",
    "      'accuracy': acc,\n",
    "      'macro_f1': macro_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca8433f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set logging steps\n",
    "logging_steps = round(len(train_dataset)/geneformer_batch_size/10)\n",
    "logging_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae65cb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/domino/geneformer_workflow/Geneformer and are newly initialized: ['classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(pretrained_model_path, \n",
    "                                                  num_labels=len(target_name_id_dict),\n",
    "                                                  output_attentions = False,\n",
    "                                                  output_hidden_states = False).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c8ec865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/domino/geneformer_workflow/results/perturbation/finetuned_model/231010_160531_geneformer_CellClassifier_L2048_B6_LR5e-05_LSlinear_WU500_E10_Oadamw_F0/'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define output directory path\n",
    "current_date = datetime.datetime.now()\n",
    "datestamp = f\"{str(current_date.year)[-2:]}{current_date.month:02d}{current_date.day:02d}_{current_date.strftime('%X').replace(':','')}\"\n",
    "output_dir = f\"{model_save_dir}/{datestamp}_geneformer_CellClassifier_L{max_input_size}_B{geneformer_batch_size}_LR{max_lr}_LS{lr_schedule_fn}_WU{warmup_steps}_E{epochs}_O{optimizer}_F{freeze_layers}/\"\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49a0329d-aca2-4ded-be35-280d0dc907eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure not overwriting previously saved model\n",
    "saved_model_test = os.path.join(output_dir, f\"pytorch_model.bin\")\n",
    "if os.path.isfile(saved_model_test) == True:\n",
    "    raise Exception(\"Model already saved to this directory.\")\n",
    "\n",
    "os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7edaf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    \"learning_rate\": max_lr,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"logging_steps\": logging_steps,\n",
    "    \"group_by_length\": True,\n",
    "    \"length_column_name\": \"length\",\n",
    "    \"disable_tqdm\": False,\n",
    "    \"lr_scheduler_type\": lr_schedule_fn,\n",
    "    \"warmup_steps\": warmup_steps,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"per_device_train_batch_size\": geneformer_batch_size,\n",
    "    \"per_device_eval_batch_size\": geneformer_batch_size,\n",
    "    \"num_train_epochs\": epochs,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"output_dir\": output_dir,\n",
    "    \"eval_accumulation_steps\": 1,  # Otherwise runs out of memory during eval\n",
    "    \"fp16\": False,\n",
    "}\n",
    "\n",
    "training_args_init = TrainingArguments(**training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0eb05dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_init,\n",
    "    data_collator=DataCollatorForCellClassification(),\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a4f11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/domino/.local/lib/python3.10/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a8f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "eba1599a1f7e611c14c87ccff6793920aa63510b01fc0e229d6dd014149b8829"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
